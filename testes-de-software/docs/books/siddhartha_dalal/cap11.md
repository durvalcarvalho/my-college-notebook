# 11. Modelos de confiabilidade de software: uma pesquisa seletiva e novos rumos

[...]

# 11.3. Modelos Dinâmicos: Modelos de Crescimento de Confiabilidade para Teste e Uso Operacional

A estimativa da confiabilidade do software determina a confiabilidade do software atual aplicando técnicas de inferência estatística aos dados de falha obtidos durante o teste do sistema ou durante a operação do sistema. Como a confiabilidade tende a melhorar com o tempo durante os períodos de teste e operação do software devido à remoção de falhas, os modelos também são chamados de modelos de crescimento de confiabilidade. Eles modelam o processo de falha subjacente do software e usam o histórico de falhas observado como uma diretriz, a fim de estimar o número residual de falhas no software e o tempo de teste necessário para detectá-las. Isso pode ser usado para tomar decisões de lançamento e implantação. A maioria dos modelos atuais de confiabilidade de software se enquadra nesta categoria. Detalhes desses modelos podem ser encontrados em Lyu, Musa et al., Singpurwalla e Wilson e Gokhale et al..

### 11.3.1 Uma classe geral de modelos

Agora descrevemos uma classe geral de modelos. Em modelos binomiais, o número total de falhas é algum número N; o número encontrado pelo tempo t tem uma distribuição binomial com média μ(t) = NF(t), onde F(t) é a probabilidade de uma falha particular ser encontrada no tempo t. Assim, o número de falhas encontradas em qualquer intervalo de tempo (incluindo o intervalo (t, ∞)) também é binomial. F(t) pode ser qualquer função de distribuição cumulativa arbitrária. Então, uma classe geral de modelos de confiabilidade é obtida pela parametrização apropriada de μ(t) eN.

Supondo que N seja Poisson (com alguma média ν), obtém-se o modelo de Poisson relacionado; agora, o número de falhas encontradas em qualquer intervalo é Poisson, e para intervalos disjuntos esses números são independentes. Denotando a derivada de F por F, a taxa de risco no tempo t é F(t) / [1 - F(t)]. Esses modelos são markovianos, mas não fortemente markovianos, exceto quando F é exponencial; variações menores deste caso foram estudadas por Jelinski e Moranda, Shooman, Schneidewind, Musa, Moranda  e Goel e Okomoto. Schick e Wolverton  e Crow  fizeram a distribuição F a Weibull; Yamada et al. fez uma distribuição Gama de F; e o modelo de Littlewood  é equivalente a assumir que F é Pareto. Musa e Okumoto  assumiram que a taxa de risco era uma função linear inversa do tempo; para este modelo de “Poisson logarítmico”, o número total de falhas é infinito.

O sucesso de um modelo é freqüentemente julgado por quão bem ele se ajusta a uma curva de confiabilidade estimada μ(t) para a função observada de “número de falhas versus tempo”. Em termos gerais, ter um bom ajuste pode ser um ajuste excessivo e pode ter pouco a ver com a utilidade do modelo na previsão de falhas futuras no sistema atual, ou experiência futura com outro sistema, a menos que possamos estabelecer relações estatísticas entre os atributos mensuráveis do sistema e os parâmetros estimados dos modelos ajustados.

<div align='center'><img src='books/siddhartha_dalal/static/figura-11-2.png'></div>

Vamos examinar o exemplo real plotado na Figura 11.2 do teste de um grande sistema de software em uma empresa de pesquisa de telecomunicações. O sistema foi desenvolvido ao longo dos anos e novas versões foram criadas e testadas pelos mesmos grupos de desenvolvimento e teste, respectivamente. Na Figura 11.2, o tempo de teste decorrido em dias da equipe t é plotado em relação ao número cumulativo de falhas encontradas para uma das liberações. Não está claro se existe algum “número total” de bugs a serem encontrados ou se o número encontrado continuará a aumentar indefinidamente. No entanto, a partir de dados como os da Figura 11.2, uma estimativa da cauda de uma distribuição com um grau razoável de precisão não é possível. Também ajustamos um caso especial do modelo geral de crescimento da confiabilidade descrito acima, correspondendo a N sendo Poisson e F sendo exponencial.

### 11.3.2 Premissas subjacentes aos modelos de crescimento de confiabilidade

Diferentes conjuntos de suposições podem levar a modelos equivalentes. Por exemplo, a suposição de que, para cada falha, o tempo de detecção é uma variável aleatória com uma distribuição de Pareto, essas variáveis aleatórias sendo independentes, é equivalente a assumir que cada falha tem um tempo de vida exponencial, com esses tempos de vida sendo independentes, e as taxas para as diferentes falhas sendo distribuídas de acordo com uma distribuição Gama (este é o modelo de Littlewood). Uma única experiência não pode distinguir entre um modelo que assume um número fixo mas desconhecido de falhas e um modelo que assume que esse número é aleatório. Pouco se sabe sobre como os vários modelos podem ser distinguidos.

A maioria dos modelos publicados é baseada em suposições subjacentes comuns. Isso geralmente inclui o seguinte.

- 1. O sistema que está sendo testado permanece essencialmente inalterado durante o teste, exceto para a remoção de falhas à medida que são encontradas. Alguns modelos permitem a possibilidade de que as falhas não sejam corrigidas perfeitamente. Miller assumiu que se as falhas não são removidas conforme são encontradas, então cada falha causa falhas de acordo com um processo de Poisson estacionário; esses processos são independentes um do outro e podem ter taxas diferentes. Ao especificar as taxas, muitos dos modelos mencionados na Seção 11.3.1 podem ser obtidos. Gokhale et al. lidou com o caso de depuração imperfeita.

- 2. A remoção de uma falha não afeta a chance de uma falha diferente ser encontrada.

- 3. O “tempo” é medido de forma que o esforço de teste seja constante. Musa relatou que o tempo de execução (tempo do processador) é a forma mais bem-sucedida de medir o tempo. Outros preferem testar o esforço medido em horas de trabalho.

- 4. O modelo é Markoviano, ou seja, a cada momento, a evolução futura do processo de teste depende apenas do estado atual (o tempo atual, o número de falhas encontradas e restantes, e os parâmetros gerais do modelo) e não de detalhes da história anterior do processo de teste. Em alguns modelos, existe uma propriedade mais forte, a saber, que o futuro depende apenas do estado atual e dos parâmetros, e não do tempo atual. Chamamos isso de propriedade “Markov forte”.

- 5. Todas as falhas são de igual importância (contribuem igualmente para a taxa de falhas). Algumas extensões foram discutidas por Dalal e Mallows no contexto de quando parar o teste.

- 6. No início do teste, existe um número total finito de falhas, que podem ser corrigidas (conhecidas ou desconhecidas) ou aleatórias; se aleatória, sua distribuição pode ser conhecida ou de forma conhecida com parâmetros desconhecidos. Alternativamente, o “número de falhas” não é considerado finito, de forma que, se o teste continuar indefinidamente, um número cada vez maior de falhas será encontrado.

- 7. Entre as falhas, a taxa de risco segue uma forma funcional conhecida; isso geralmente é considerado simplesmente uma constante.

### 11.3.3 Cuidado ao usar modelos de crescimento de confiabilidade

Aqui, também gostaríamos de oferecer alguns cuidados aos leitores em relação ao uso de modelos de confiabilidade de software.

Ao ajustar qualquer modelo a um determinado conjunto de dados, deve-se primeiro ter em mente as suposições de um determinado modelo. Por exemplo, se um modelo assume que um número fixo de falhas de software será removido dentro de um período de tempo limitado, mas no processo observado o número de falhas não é corrigido (por exemplo, novas falhas são inseridas devido à remoção de falha imperfeita ou novo código é adicionado), então deve-se usar outro modelo que não faça essa suposição.

Uma segunda limitação do modelo e problema de implementação diz respeito a previsões futuras. Se o software estiver sendo operado de uma maneira diferente da forma como é testado (por exemplo, novos recursos estão sendo exercidos que não foram testados antes), o histórico de falhas do passado não refletirá essas mudanças e podem resultar em previsões ruins. Desenvolvimento de perfis operacionais, conforme proposto por Musa et al., é muito importante se se deseja prever a confiabilidade futura com precisão no ambiente do usuário.

Outra questão está relacionada ao ambiente de desenvolvimento de software. A maioria dos modelos de crescimento de confiabilidade são aplicáveis ​​principalmente a partir dos testes: presume-se que o software tenha amadurecido a ponto de não serem feitas alterações extensas. Esses modelos não podem ter um desempenho confiável quando o software está mudando e a rotatividade do código do software é observada durante o teste. Nesse caso, as técnicas descritas na Seção 11.4 devem ser usadas para lidar com a situação de teste dinâmico.

## 11.4 Modelagem de Crescimento de Confiabilidade com Covariáveis

Até agora, discutimos vários tipos diferentes de modelo de confiabilidade de vários graus de plausibilidade, incluindo modelos baseados em fase, dependendo de uma curva de Raleigh, modelos de crescimento como o modelo Goel-Okumoto, etc. Os modelos de crescimento tomam como entrada o tempo de falha ou dados de contagem de falhas e ajustar um modelo de processo estocástico para refletir o crescimento da confiabilidade. As diferenças entre os modelos residem principalmente nas suposições feitas no processo estocástico subjacente que gera os dados.

No entanto, a maioria dos modelos existentes assume que nenhuma variável explicativa está disponível. Essa suposição é seguramente simplista, quando os modelos são usados ​​para modelar um processo de teste, para todos os sistemas, exceto pequenos que envolvem desenvolvimento e ciclos de vida curtos. Para grandes sistemas (por exemplo, maior do que 100 KNCSL, ou seja, milhares de linhas de fonte não comentários), existem variáveis, além do tempo, que são muito relevantes. Por exemplo, é normalmente assumido que o número de falhas (encontradas e não encontradas) em um sistema em teste permanece estável durante o teste. Isso significa que o código permanece congelado durante o teste. No entanto, isso raramente é o caso para sistemas grandes, uma vez que os ciclos de entrega agressivos forçam as fases finais de desenvolvimento a se sobreporem aos estágios iniciais do teste do sistema. Assim, o tamanho do código e, conseqüentemente, o número de falhas em um sistema grande pode variar amplamente durante o teste. Se essas mudanças no tamanho do código não forem consideradas como uma covariável, é provável que haja, na melhor das hipóteses, um aumento na variabilidade e uma perda no desempenho preditivo; na pior das hipóteses, um modelo de ajuste ruim com estimativas de parâmetros instáveis ​​é provável. Descrevemos brevemente uma abordagem geral proposta por Dalal e McIntosh para incorporar covariáveis ​​junto com um estudo de caso que trata da modelagem de confiabilidade durante o teste do produto quando o código está mudando.

### 11.4.1 Exemplo 1

Considere uma nova versão de um grande sistema de telecomunicações com aproximadamente 7 milhões de NCSL e 300 KNCNCSL (ou seja, milhares de linhas de fontes novas ou alteradas sem comentários). Para um ciclo de entrega mais rápido, o código-fonte usado para o teste do sistema foi atualizado todas as noites durante o período de teste. No final de cada um dos 198 dias corridos no ciclo de teste, o número de falhas encontradas, NCNCSL e o tempo da equipe gasto nos testes foram coletados. A Figura 11.3 retrata o crescimento do sistema em termos de NCNCSL e de falhas em relação ao tempo do pessoal. Os dados numéricos correspondentes são fornecidos em Dalal e McIntosh.

<div align='center'><img src='books/siddhartha_dalal/static/figura-11-3.png'></div>


Suponha que o processo de teste seja observado no tempo t i, i = 0,. . . , h, e a qualquer momento o tempo necessário para encontrar um bug específico é exponencial com a taxa m. No tempo t i, o número total de falhas restantes no sistema é Poisson com média l i + 1, e NCNCSL é aumentado em um valor C i. Essa alteração adiciona um número de Poisson de falhas com média proporcional a C, digamos qC i. Essas suposições levam à equação do balanço de massa, ou seja, que o número esperado de falhas no sistema em ti (após possível modificação) é o número esperado de falhas no sistema em ti − 1 ajustado pelo número esperado encontrado no intervalo (ti -1, ti) mais as falhas introduzidas pelas mudanças feitas em ti:

<div align='center'><img src='books/siddhartha_dalal/static/formula-01.png'></div>

para i = 1,. . . , h. Observe que q representa o número de novas falhas entrando no sistema por NCNCSL adicional e l 1 representa o número de falhas no código no início do teste do sistema. Ambos os parâmetros tornam possível diferenciar entre o novo código adicionado na versão atual e o código antigo. Para o exemplo, os parâmetros estimados são q = 0,025, m = 0,002 e l 1 = 41. Os dados ajustados e observados são plotados em relação ao tempo da equipe na Figura 11.3 (parte inferior). O ajuste é evidentemente muito bom. Obviamente, avaliar o modelo em dados independentes ou novos é necessário para uma validação adequada.

Agora examinamos a eficácia da criação de um modelo estatístico. A estimativa de q no exemplo é altamente significativa, tanto estatisticamente quanto na prática, mostrando a necessidade de incorporar mudanças no NCNCSL como uma covariável. Seu valor numérico implica que, para cada 10.000 NCNCSL adicionais adicionados ao sistema, 25 falhas também estão sendo adicionadas. Para esses dados, o número previsto de falhas no final do período de teste é Poisson distribuído com a média 145. Dividindo essa quantidade pelo NCNCSL total, dá 4,2 por 10.000 NCNCSL como uma densidade de falha de campo estimada. Essas estimativas da qualidade de entrada e saída são valiosas para julgar a eficácia dos testes do sistema e para decidir onde os recursos devem ser alocados para melhorar a qualidade. Aqui, por exemplo, o teste do sistema foi eficaz, pois removeu 21 de cada 25 falhas. No entanto, isso levanta outra questão: 25 falhas por 10.000 NCNCSL entrando no teste do sistema pode ser muito alto e um plano deve ser considerado para melhorar a qualidade de entrada.

Nenhuma das conclusões acima poderia ter sido feita sem o uso de um modelo estatístico. Essas conclusões são valiosas para controlar e melhorar o processo. Além disso, para esta análise foi essencial ter uma covariável diferente de tempo.

## 11.5. Quando parar de testar o software

Os modelos de crescimento de confiabilidade dinâmica podem ser usados ​​para tomar decisões sobre quando interromper o teste.

O teste de software é um processo necessário, mas caro, consumindo de um terço a metade do custo de um projeto de desenvolvimento típico. Testar um grande sistema de software custa milhares de dólares por dia. Testes excessivamente zelosos podem levar a um produto com preço excessivo e atrasado no mercado, ao passo que consertar uma falha em um sistema liberado costuma ser uma ordem de magnitude mais caro do que consertar a falha no laboratório de testes. Portanto, a questão de quanto testar é uma questão econômica importante. Discutimos uma formulação econômica da questão “quando parar de testar” proposta por Dalal e Mallows. Outras formulações foram propostas por Dalal e Mallows e por Singpurwalla.

Como muitos outros modelos de confiabilidade, o modelo estocástico de Dalal e Mallows assume que há N falhas (desconhecidas) no software e os tempos para encontrar falhas são observáveis ​​e são i.i.d. exponencial com taxa m. N é Poisson (l), e que l é Gamma (a, b). Além disso, seu modelo econômico define o custo do teste no tempo t como sendo f t - cK (t), onde K (t) é o número de falhas observadas no tempo t e f é o custo de operação do laboratório de teste por unidade de tempo. A constante c é o custo líquido de consertar uma falha depois, e não antes da liberação. Sob suposições um pouco mais gerais, Dalal e Mallows encontraram a regra de parada ideal exata. A estrutura da regra exata, que é baseada na programação dinâmica estocástica, é bastante complexa. No entanto, para N grande, que é necessariamente o caso para sistemas grandes, a regra de parada ótima é: pare assim que f (e mt - 1) / (mc) ≥ K (t). Para além da garantia económica, esta regra dá uma garantia sobre o número de faltas remanescentes, nomeadamente que este número tem uma distribuição de Poisson com média f / (mc). Assim, ao invés de determinar a razão f / c a partir de considerações econômicas, podemos escolhê-la de forma que haja garantias probabilísticas sobre o número de faltas remanescentes. Alguns profissionais podem achar que esta garantia probabilística sobre o número de falhas restantes é mais relevante em sua aplicação. (Ver Dalal e Mallows para uma discussão mais detalhada.) Finalmente, usando um raciocínio semelhante ao usado na derivação da equação (4.5) de Dalal e Mallows, pode ser mostrado que a estimativa atual do tempo adicional necessário para o teste Δt, é dado por

<div align='center'><img src='books/siddhartha_dalal/static/formula-02.png'></div>

## 11.6 Desafios e conclusões

A modelagem e medição de confiabilidade de software têm atraído bastante atenção recentemente em vários setores devido a preocupações com a qualidade do software. Muitos modelos de confiabilidade foram propostos, muitas histórias de sucesso foram relatadas, várias conferências e fóruns foram formados e muita experiência em projetos foi compartilhada.

Apesar disso, existem muitos desafios em obter o uso generalizado de modelos de confiabilidade de software. Parte do desafio é que o teste e outras atividades não são tão compartimentadas como assumido nos modelos. Conforme discutido na Seção 11.4, a rotatividade de código ocorre constantemente durante os testes e, exceto para o modelo Dalal e McIntosh descrito na Seção 11.4, há muito pouco trabalho nessa área. Além disso, para fins de tomada de decisão durante as fases de teste e implantação, gostaria de ter uma estimativa rápida da confiabilidade do sistema. Esperar para coletar uma quantidade substancial de dados antes de ser capaz de ajustar um modelo não é viável em muitos ambientes. Aproveitar as informações das fases iniciais do ciclo de vida de desenvolvimento para chegar a um modelo rápido e confiável amenizaria essa dificuldade. Uma extensão da abordagem descrita na Seção 11.2.2 parece ser necessária. Olhando para o futuro, também valeria a pena incorporar a arquitetura do sistema para fazer estimativas preliminares; para uma pesquisa de modelos de confiabilidade baseados em arquitetura, consulte Goševa-Popstojanova e Trivedi. Finalmente, em grande parte, os modelos de crescimento de confiabilidade usados ​​no campo não aproveitam as informações sobre os casos de teste usados. Um dos motivos é que cada caso de teste é considerado único. No entanto, conforme estamos avançando na área de teste baseado em modelo, a criação de caso de teste é suportada por um metamodelo subjacente dos casos de uso e restrições impostas pelos usuários. Criar novos modelos de confiabilidade aproveitando esses metamodelos seria importante.

Em conclusão, neste capítulo, descrevemos os principais modelos de confiabilidade de software para os estágios iniciais, bem como para as fases de teste e operacional, e demos alguns exemplos de seus usos. Também propusemos algumas novas direções de pesquisa úteis para os profissionais, que levarão a um uso mais amplo de modelos de confiabilidade de software.
